// í”„ë¡ íŠ¸ì—”ë“œ ê¸°ë°˜ ìŒì„± ì„œë¹„ìŠ¤ (Web Speech API STT + RealTans TTS)
import { STTResponse, TTSResponse, VoiceSettings } from '../types/voice';

export class FrontendVoiceService {
  private static openaiApiKey: string | null = null;
  private static realTansApiKey: string | null = null;

  // ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
  private static async checkNetworkConnection(): Promise<boolean> {
    // Web Speech APIëŠ” ë¸Œë¼ìš°ì € ë‚´ì¥ ê¸°ëŠ¥ì´ë¯€ë¡œ ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ ë¶ˆí•„ìš”
    // ë¸Œë¼ìš°ì €ê°€ Web Speech APIë¥¼ ì§€ì›í•˜ëŠ”ì§€ë§Œ í™•ì¸í•˜ë©´ ë¨
    return true;
  }

  // API í‚¤ ì„¤ì •
  static setApiKeys(openaiKey: string, realTansKey: string) {
    this.openaiApiKey = openaiKey;
    this.realTansApiKey = realTansKey;
  }

  // STT: Web Speech API ì‚¬ìš© (API í‚¤ ë¶ˆí•„ìš”)
  static async speechToTextWebSpeech(language: string = 'ko-KR', retryCount: number = 0): Promise<STTResponse> {
    const maxRetries = 2; // ìµœëŒ€ 2ë²ˆ ì¬ì‹œë„
    
    return new Promise((resolve, reject) => {
      // Web Speech API ì§€ì› í™•ì¸
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        reject(new Error('ì´ ë¸Œë¼ìš°ì €ëŠ” Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome, Edge, Safarië¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.'));
        return;
      }

      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();

      // íƒ€ì„ì•„ì›ƒ ì„¤ì • (10ì´ˆ)
      const timeoutId = setTimeout(() => {
        recognition.stop();
        reject(new Error('ìŒì„± ì¸ì‹ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'));
      }, 10000);

      // Web Speech API ì„¤ì • ìµœì í™”
      recognition.continuous = false;
      recognition.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ë„ ë°›ì•„ì„œ ë” ë¹ ë¥¸ í”¼ë“œë°±
      recognition.lang = language;
      recognition.maxAlternatives = 1; // ìµœëŒ€ ëŒ€ì•ˆ ìˆ˜ ì œí•œ
      
      // Web Speech APIëŠ” ë¸Œë¼ìš°ì € ë‚´ì¥ ê¸°ëŠ¥ì´ë¯€ë¡œ ì™¸ë¶€ API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • ë¶ˆí•„ìš”
      // serviceURI ì„¤ì •ì„ ì œê±°í•˜ì—¬ ë¸Œë¼ìš°ì €ì˜ ê¸°ë³¸ Web Speech API ì‚¬ìš©

      let hasResult = false;

      recognition.onstart = () => {
        console.log('ğŸ¤ Web Speech API ìŒì„± ì¸ì‹ ì‹œì‘');
        clearTimeout(timeoutId);
      };

      recognition.onresult = (event: any) => {
        if (hasResult) return; // ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
        
        const result = event.results[event.results.length - 1];
        const transcript = result[0].transcript;
        const confidence = result[0].confidence;
        
        console.log('ğŸ¤ Web Speech API ì¸ì‹ ê²°ê³¼:', {
          transcript,
          confidence,
          isFinal: result.isFinal
        });
        
        // ì¤‘ê°„ ê²°ê³¼ë„ ì²˜ë¦¬ (ë” ë¹ ë¥¸ ì‘ë‹µ)
        if (transcript.trim().length > 0) {
          // ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
          if (result.isFinal) {
            hasResult = true;
            clearTimeout(timeoutId);
            
            // ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° (0.2 ë¯¸ë§Œ) ì¬ì‹œë„ ì œì•ˆ (ì„ê³„ê°’ ë‚®ì¶¤)
            if (confidence < 0.2) {
              console.warn('ğŸ¤ ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¸ì‹ë¨:', { transcript, confidence });
              if (retryCount < maxRetries) {
                console.log(`ğŸ”„ ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¸í•œ ì¬ì‹œë„ ${retryCount + 1}/${maxRetries}`);
                setTimeout(() => {
                  this.speechToTextWebSpeech(language, retryCount + 1)
                    .then(resolve)
                    .catch(reject);
                }, 1000 * (retryCount + 1));
                return;
              }
              reject(new Error('ìŒì„±ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” ì²œì²œíˆ ë§ì”€í•´ì£¼ì„¸ìš”.'));
              return;
            }
            
            // í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš° (1ê¸€ì ë¯¸ë§Œ) ì¬ì‹œë„ ì œì•ˆ (ì„ê³„ê°’ ë‚®ì¶¤)
            if (transcript.trim().length < 1) {
              console.warn('ğŸ¤ ë„ˆë¬´ ì§§ì€ ìŒì„±:', transcript);
              if (retryCount < maxRetries) {
                console.log(`ğŸ”„ ì§§ì€ ìŒì„±ìœ¼ë¡œ ì¸í•œ ì¬ì‹œë„ ${retryCount + 1}/${maxRetries}`);
                setTimeout(() => {
                  this.speechToTextWebSpeech(language, retryCount + 1)
                    .then(resolve)
                    .catch(reject);
                }, 1000 * (retryCount + 1));
                return;
              }
              reject(new Error('ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.'));
              return;
            }
            
            console.log('ğŸ¤ ìµœì¢… ì¸ì‹ ê²°ê³¼:', { transcript: transcript.trim(), confidence });
            
            resolve({
              success: true,
              message: 'ìŒì„± ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
              text: transcript.trim(),
              language: language,
              duration: 0
            });
          }
          // ì¤‘ê°„ ê²°ê³¼ë„ ì²˜ë¦¬ (ë” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´)
          else if (transcript.trim().length >= 3 && confidence > 0.5) {
            hasResult = true;
            clearTimeout(timeoutId);
            
            console.log('ğŸ¤ ì¤‘ê°„ ê²°ê³¼ë¡œ ì¸ì‹ ì™„ë£Œ:', { transcript: transcript.trim(), confidence });
            
            resolve({
              success: true,
              message: 'ìŒì„± ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
              text: transcript.trim(),
              language: language,
              duration: 0
            });
          }
        }
      };

      recognition.onerror = (event: any) => {
        console.error('Web Speech API ì˜¤ë¥˜:', event.error);
        clearTimeout(timeoutId);
        
        let errorMessage = 'ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
        
        switch (event.error) {
          case 'no-speech':
            errorMessage = 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆì´í¬ì— ë” ê°€ê¹Œì´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”.';
            break;
          case 'audio-capture':
            errorMessage = 'ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
            break;
          case 'not-allowed':
            errorMessage = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
            break;
          case 'network':
            if (retryCount < maxRetries) {
              console.log(`ğŸ”„ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ì¸í•œ ì¬ì‹œë„ ${retryCount + 1}/${maxRetries}`);
              setTimeout(() => {
                this.speechToTextWebSpeech(language, retryCount + 1)
                  .then(resolve)
                  .catch(reject);
              }, 2000 * (retryCount + 1)); // ì¬ì‹œë„ ê°„ê²© ì¦ê°€
              return;
            }
            errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
            break;
          case 'aborted':
            errorMessage = 'ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
            break;
          case 'service-not-allowed':
            errorMessage = 'ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ê°€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. HTTPS í™˜ê²½ì—ì„œ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
            break;
          case 'bad-grammar':
            errorMessage = 'ìŒì„± ì¸ì‹ ë¬¸ë²• ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
            break;
          case 'aborted':
            errorMessage = 'ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.';
            break;
          default:
            errorMessage = `ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${event.error}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`;
            break;
        }
        
        reject(new Error(errorMessage));
      };

      recognition.onend = () => {
        console.log('ğŸ¤ Web Speech API ìŒì„± ì¸ì‹ ì¢…ë£Œ');
        clearTimeout(timeoutId);
        
        // ê²°ê³¼ê°€ ì—†ì´ ì¢…ë£Œëœ ê²½ìš° - ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
        if (!hasResult) {
          if (retryCount < maxRetries) {
            console.log(`ğŸ”„ ìŒì„± ë¯¸ê°ì§€ë¡œ ì¸í•œ ì¬ì‹œë„ ${retryCount + 1}/${maxRetries}`);
            setTimeout(() => {
              this.speechToTextWebSpeech(language, retryCount + 1)
                .then(resolve)
                .catch(reject);
            }, 1000 * (retryCount + 1)); // ì¬ì‹œë„ ê°„ê²©
            return;
          }
          reject(new Error('ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆì´í¬ì— ë” ê°€ê¹Œì´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”.'));
        }
      };

      // Web Speech APIëŠ” ë¸Œë¼ìš°ì € ë‚´ì¥ ê¸°ëŠ¥ì´ë¯€ë¡œ ë°”ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘
      try {
        recognition.start();
      } catch (error) {
        clearTimeout(timeoutId);
        reject(new Error('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.'));
      }
    });
  }

  // STT: OpenAI Whisper API ì‚¬ìš© (ê³ í’ˆì§ˆ, API í‚¤ í•„ìš”)
  static async speechToTextWhisper(audioBlob: Blob, language: string = 'ko'): Promise<STTResponse> {
    if (!this.openaiApiKey) {
      throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    try {
      console.log('ğŸ¤ OpenAI Whisper STT í˜¸ì¶œ:', {
        fileSize: audioBlob.size,
        fileType: audioBlob.type,
        language
      });

      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.wav');
      formData.append('model', 'whisper-1');
      formData.append('language', language);

      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.openaiApiKey}`,
        },
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`OpenAI Whisper API ì˜¤ë¥˜: ${response.status} - ${errorData.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
      }

      const result = await response.json();
      console.log('ğŸ¤ Whisper STT ì‘ë‹µ:', result);

      return {
        success: true,
        message: 'ìŒì„± ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
        text: result.text,
        language: language,
        duration: audioBlob.size // ëŒ€ëµì ì¸ ì§€ì†ì‹œê°„ ì¶”ì •
      };
    } catch (error) {
      console.error('Whisper STT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  // STT: ìë™ ì„ íƒ (Web Speech API ìš°ì„ , Whisper API ëŒ€ì²´)
  static async speechToText(audioBlob: Blob, language: string = 'ko'): Promise<STTResponse> {
    // Web Speech APIë¥¼ ë¨¼ì € ì‹œë„
    try {
      return await this.speechToTextWebSpeech(language === 'ko' ? 'ko-KR' : 'en-US');
    } catch (webSpeechError) {
      console.warn('Web Speech API ì‹¤íŒ¨, Whisper APIë¡œ ëŒ€ì²´:', webSpeechError);
      
      // Whisper APIê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
      if (this.openaiApiKey) {
        return await this.speechToTextWhisper(audioBlob, language);
      }
      
      // ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ Web Speech API ì˜¤ë¥˜ ë°˜í™˜
      throw webSpeechError;
    }
  }

  // TTS: RealTans API ì‚¬ìš©
  static async textToSpeech(text: string, settings?: Partial<VoiceSettings>): Promise<TTSResponse> {
    if (!this.realTansApiKey) {
      throw new Error('RealTans API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    try {
      console.log('ğŸ”Š RealTans TTS í˜¸ì¶œ:', {
        text: text.substring(0, 50) + '...',
        language: settings?.language || 'ko',
        voice: settings?.voice || 'default'
      });

      const response = await fetch('https://api.realtans.com/v1/tts', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.realTansApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: text,
          voice: settings?.voice || 'default',
          language: settings?.language || 'ko',
          speed: settings?.speed || 1.0,
          pitch: settings?.pitch || 1.0,
          volume: settings?.volume || 0.9
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`RealTans TTS API ì˜¤ë¥˜: ${response.status} - ${errorData.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
      }

      const audioBlob = await response.blob();
      const audioData = await this.blobToBase64(audioBlob);

      console.log('ğŸ”Š RealTans TTS ì‘ë‹µ:', {
        size: audioBlob.size,
        type: audioBlob.type
      });

      return {
        success: true,
        message: 'ìŒì„± í•©ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
        audio_data: audioData,
        duration: audioBlob.size // ëŒ€ëµì ì¸ ì§€ì†ì‹œê°„ ì¶”ì •
      };
    } catch (error) {
      console.error('RealTans TTS API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  // Blobì„ Base64ë¡œ ë³€í™˜
  private static async blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        resolve(result.split(',')[1]); // data:audio/wav;base64, ë¶€ë¶„ ì œê±°
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  // ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ìƒ
  static playAudio(audioData: string): void {
    const audio = new Audio(`data:audio/wav;base64,${audioData}`);
    audio.play().catch(error => {
      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
    });
  }

  // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° ë…¹ìŒ ì‹œì‘
  static async startRecording(): Promise<MediaRecorder> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000, // Whisperì— ìµœì í™”ëœ ìƒ˜í”Œë ˆì´íŠ¸
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus' // ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•œ í˜•ì‹
      });
      
      return mediaRecorder;
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      throw new Error('ë§ˆì´í¬ ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
    }
  }

  // ë…¹ìŒ ì¤‘ì§€ ë° ì˜¤ë””ì˜¤ ë°ì´í„° ë°˜í™˜
  static stopRecording(mediaRecorder: MediaRecorder): Promise<Blob> {
    return new Promise((resolve, reject) => {
      const chunks: BlobPart[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        resolve(blob);
      };

      mediaRecorder.onerror = (event) => {
        reject(new Error('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'));
      };

      mediaRecorder.stop();
    });
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (API í‚¤ ìœ íš¨ì„± ê²€ì‚¬)
  static async checkHealth(): Promise<{ status: string; stt_available: boolean; tts_available: boolean }> {
    const hasOpenAIKey = !!this.openaiApiKey;
    const hasRealTansKey = !!this.realTansApiKey;

    return {
      status: hasOpenAIKey && hasRealTansKey ? 'healthy' : 'unhealthy',
      stt_available: hasOpenAIKey,
      tts_available: hasRealTansKey
    };
  }

  // API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
  static async validateApiKeys(): Promise<{ openai_valid: boolean; realTans_valid: boolean }> {
    const results = { openai_valid: false, realTans_valid: false };

    // OpenAI API í‚¤ ê²€ì¦
    if (this.openaiApiKey) {
      try {
        const response = await fetch('https://api.openai.com/v1/models', {
          headers: {
            'Authorization': `Bearer ${this.openaiApiKey}`,
          },
        });
        results.openai_valid = response.ok;
      } catch (error) {
        console.warn('OpenAI API í‚¤ ê²€ì¦ ì‹¤íŒ¨:', error);
      }
    }

    // RealTans API í‚¤ ê²€ì¦
    if (this.realTansApiKey) {
      try {
        const response = await fetch('https://api.realtans.com/v1/voices', {
          headers: {
            'Authorization': `Bearer ${this.realTansApiKey}`,
          },
        });
        results.realTans_valid = response.ok;
      } catch (error) {
        console.warn('RealTans API í‚¤ ê²€ì¦ ì‹¤íŒ¨:', error);
      }
    }

    return results;
  }
}
